{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats import diagnostic\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and wrangling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data_tesco/'\n",
    "\n",
    "GROCERY_WARD = 'year_osward_grocery.csv'\n",
    "GROCERY_BOROUGH = 'year_borough_grocery.csv'\n",
    "\n",
    "DIABETES_WARD = 'diabetes_estimates_osward_2016.csv'\n",
    "OBESITY_BOROUGH = 'london_obesity_borough_2012.csv'\n",
    "CHILD_OBESITY_WARD = 'child_obesity_london_ward_2013-2014.csv'\n",
    "\n",
    "MAPPING_BOROUGH_WARD = 'Mapping-template-london-ward-map-2018.xls'\n",
    "MAPPING_CODE_BOROUGH = 'Mapping-template-for-London-boroughs.xls'\n",
    "\n",
    "BOUNDARIES_BOROUGH = 'statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp'\n",
    "\n",
    "CONSUMER_EXPENDITURE_BOROUGH = 'detailed-borough-base.xls'\n",
    "CHILDREN_POVERTY_BOROUGH = 'children-in-poverty.xls'\n",
    "EARNINGS_BOROUGH = 'earnings-residence-borough.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grocery data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries_borough = pd.read_csv(PATH + GROCERY_BOROUGH, sep = ',', header = 0)\n",
    "groceries_ward = pd.read_csv(PATH + GROCERY_WARD, sep = ',', header = 0)\n",
    "# Consider representativeness?\n",
    "groceries_borough = groceries_borough[groceries_borough['representativeness_norm'] >= 0.1]\n",
    "groceries_ward = groceries_ward[groceries_ward['representativeness_norm'] >= 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ward to borough mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_ward_to_borough = pd.read_excel(MAPPING_BOROUGH_WARD, sheet_name = 'Ward Thematic Map',usecols = [0, 1, 2],\n",
    "                                        names = ['Ward Code', 'Ward name', 'Borough name'])\n",
    "mapping_code_to_borough = pd.read_excel(MAPPING_CODE_BOROUGH, sheet_name = 'Borough Thematic Map',usecols = [1, 2],\n",
    "                                       names = ['Borough Code', 'Borough name'])\n",
    "mapping_ward_to_borough = mapping_ward_to_borough.merge(mapping_code_to_borough, on = 'Borough name')\n",
    "mapping_ward_to_borough = mapping_ward_to_borough.drop(columns = ['Ward name', 'Borough name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Health data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data (diabetes) are only available for borough, thus we average all wards part of a same borough and map the data to the corresponding borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes\n",
    "diabetes_ward = pd.read_csv(PATH + DIABETES_WARD, sep = ',', header = 0)\n",
    "diabetes_ward = diabetes_ward.merge(mapping_ward_to_borough, left_on = 'area_id', right_on = 'Ward Code')\n",
    "diabetes_ward = diabetes_ward.drop(columns = ['Ward Code'])\n",
    "diabetes_borough = diabetes_ward.groupby(['Borough Code'], as_index = False).mean()\n",
    "len(diabetes_borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obesity\n",
    "obesity_borough = pd.read_csv(PATH + OBESITY_BOROUGH, sep = ',', header = 0)\n",
    "len(obesity_borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Child obesity ward\n",
    "child_obesity_ward = pd.read_csv(PATH + CHILD_OBESITY_WARD, sep = ',', header = 0)\n",
    "to_drop = child_obesity_ward[ (child_obesity_ward['prevalence_overweight_reception'] == 'na')\n",
    "                             | (child_obesity_ward['prevalence_overweight_y6'] == 'na')\n",
    "                            | (child_obesity_ward['prevalence_obese_reception'] == 'na')\n",
    "                            | (child_obesity_ward['prevalence_obese_y6'] == 'na')].index\n",
    "child_obesity_ward.drop(to_drop , inplace=True)\n",
    "child_obesity_ward = child_obesity_ward.merge(mapping_ward_to_borough, left_on = 'area_id', right_on = 'Ward Code')\n",
    "child_obesity_ward = child_obesity_ward.drop(columns = ['Ward Code'])\n",
    "child_obesity_ward = child_obesity_ward.astype({'number_reception_measured': 'float64',\n",
    "          'number_y6_measured': 'float64',\n",
    "          'prevalence_overweight_reception': 'float64',\n",
    "          'prevalence_overweight_y6': 'float64',\n",
    "          'prevalence_obese_reception': 'float64',\n",
    "          'prevalence_obese_y6': 'float64'})\n",
    "child_obesity_borough = child_obesity_ward.groupby(['Borough Code'], as_index = False).mean()\n",
    "len(child_obesity_borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data for wards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ward = pd.merge(diabetes_ward, groceries_ward, how = 'inner', left_index = False, on='area_id')\n",
    "merged_ward.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data for boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(groceries_borough, obesity_borough, how = 'inner', left_index = False, left_on='area_id',\n",
    "                         right_on = 'oslaua')\n",
    "merged = pd.merge(merged, child_obesity_borough, how = 'inner', left_index = False, left_on='area_id',\n",
    "                         right_on = 'Borough Code')\n",
    "merged_borough = pd.merge(merged, diabetes_borough, how = 'inner', left_index = False, left_on='area_id',\n",
    "                         right_on = 'Borough Code')\n",
    "print(len(merged_borough))\n",
    "merged_borough.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and merge boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_borough = gpd.read_file(BOUNDARIES_BOROUGH)\n",
    "merged = map_borough.merge(merged_borough, left_on = 'GSS_CODE', right_on = 'area_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Economic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_poverty = pd.read_excel(PATH+CHILDREN_POVERTY_BOROUGH, sheet_name = '2015',usecols = [0, 5],\n",
    "                                        names = ['area_id', 'child_poverty'])\n",
    "children_poverty = children_poverty.loc[21:53]\n",
    "children_poverty = children_poverty.astype({'child_poverty': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings = pd.read_excel(PATH+EARNINGS_BOROUGH, sheet_name = 'Full-time, Weekly',usecols = [1, 28],\n",
    "                                       names = ['Borough name', 'earnings'], na_values=['#'])\n",
    "earnings = earnings.loc[2:34]\n",
    "earnings = earnings.astype({'earnings': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_expenditure = pd.read_excel(PATH+CONSUMER_EXPENDITURE_BOROUGH, sheet_name = 'Greater London',usecols = [0, 1, 17],\n",
    "                                        names = ['Borough name', 'type', 'expenditure'], skiprows=[0, 1, 2])\n",
    "consumer_expenditure.dropna(inplace=True)\n",
    "consumer_expenditure.sort_values(by=['Borough name'], inplace=True)\n",
    "consumer_expenditure = consumer_expenditure.pivot_table(values='expenditure', index='Borough name', columns='type')\n",
    "consumer_expenditure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_expenditure = consumer_expenditure.transform(lambda x: (x / x.sum()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize prevalence of diabetes and obesity/overweight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there's a correlation between the indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = ['estimated_diabetes_prevalence', 'prevalence_obese_reception', 'prevalence_obese_y6','f_obese', 'prevalence_overweight_reception', 'prevalence_overweight_y6', 'f_overweight']\n",
    "df = merged_borough[indicators]\n",
    "\n",
    "mask = np.triu(np.ones_like(df.corr(), dtype=np.bool))\n",
    "heatmap = sns.heatmap(df.corr(method='spearman'), vmin=-1, vmax=1, mask = mask, annot=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if those indicators are correlated with any food habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We partition 'types' of food habits\n",
    "energy_nutrients = ['energy_tot', 'energy_fat', 'energy_saturate', 'energy_sugar', 'energy_protein', 'energy_carb', \n",
    "                    'energy_fibre', 'energy_alcohol'] #'h_nutrients_calories'\n",
    "f_food_categories = ['f_beer', 'f_dairy', 'f_eggs', 'f_fats_oils', 'f_fish', 'f_fruit_veg', 'f_grains',\n",
    "                   'f_meat_red', 'f_poultry', 'f_readymade', 'f_sauces', 'f_soft_drinks', 'f_spirits',\n",
    "                   'f_sweets', 'f_tea_coffee', 'f_water', 'f_wine']\n",
    "features = energy_nutrients + f_food_categories\n",
    "indicators = ['estimated_diabetes_prevalence', 'f_overweight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(8, 8))\n",
    "\n",
    "for i, ind in enumerate(indicators):\n",
    "    labels = features.copy()\n",
    "    labels.append(ind)\n",
    "    df = merged_borough[labels]\n",
    "    heatmap = sns.heatmap(df.corr(method='spearman')[[ind]].sort_values(by = ind, ascending=False), vmin=-1, vmax=1, annot=True, ax=axs[i])\n",
    "    heatmap.set_title(ind, fontdict={'fontsize':12})\n",
    "    \n",
    "plt.subplots_adjust(wspace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fancy plot sur le notebook de Mama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize average diet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot nutrient and category repartition in average diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_nutrients = pd.DataFrame(groceries_ward.mean(axis = 0)[energy_nutrients], columns = ['nutrient'])\n",
    "average_categories = pd.DataFrame(groceries_ward.mean(axis = 0)[f_food_categories], columns = ['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients_labels = ['Energy tot', 'Energy fat', 'Energy saturate', 'Energy sugar', 'Energy protein', 'Energy carb', \n",
    "                    'Energy fibre', 'Energy alcohol']\n",
    "food_labels = ['Beer', 'Dairy', 'Eggs', 'Fats & oils', 'Fish', 'Fruit & veg', 'Grains',\n",
    "                   'Red meat', 'Poultry', 'Readymade', 'Sauces', 'Soft drinks', 'Spirits',\n",
    "                   'Sweets', 'Tea & coffee', 'Water', 'Wine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = go.Figure(data=[go.Pie( \n",
    "    name='Nutrients', \n",
    "    values=average_nutrients['nutrient'], \n",
    "    labels=nutrients_labels,\n",
    "    marker_colors=px.colors.sequential.Viridis,\n",
    "    textposition='inside',\n",
    "    hoverinfo='percent+label',\n",
    "    insidetextorientation='auto',\n",
    "    hole=0.5\n",
    "), \n",
    "    go.Pie( \n",
    "    name='Food', \n",
    "    values=average_categories['category'], \n",
    "    labels=food_labels,\n",
    "    marker_colors=px.colors.sequential.Viridis,\n",
    "    textposition='inside',\n",
    "    hoverinfo='percent+label',\n",
    "    insidetextorientation='auto',\n",
    "    hole=0.5\n",
    ") \n",
    "]) \n",
    "  \n",
    "plot.update_layout( \n",
    "    updatemenus=[ \n",
    "        dict( \n",
    "            active=0, \n",
    "            buttons=list([  \n",
    "                dict(label=\"Nutrient categories\", \n",
    "                     method=\"update\", \n",
    "                     args=[{\"visible\": [True, False]}, \n",
    "                           {\"title\": \"Londoners Average Diet\", \n",
    "                            }]), \n",
    "                dict(label=\"Food categories\", \n",
    "                     method=\"update\", \n",
    "                     args=[{\"visible\": [False, True]}, \n",
    "                           {\"title\": \"Londoners Average Diet\", \n",
    "                            }]), \n",
    "            ]), \n",
    "        ) \n",
    "    ]) \n",
    "  \n",
    "plot.write_html(\"figures/piecharts.html\")    \n",
    "plot.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the average diet to the WHO recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute 5 criterias that make a diet healthy and that are either 0 or 1 depending on if they are fulfilled or not: fat criteria (< 30% of total energy intake), saturated fat criteria (< 10% of total energy intake), sugars criteria (< 10% of total energy intake), etc... We obtain a final score between 0 and 5, out of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total fat should not exceed 30% of total energy intake\n",
    "groceries_borough['WHO_totalfat'] = 0\n",
    "groceries_borough.loc[(groceries_borough['energy_fat'] <= 0.3*groceries_borough['energy_tot']), 'WHO_totalfat'] = 1\n",
    "groceries_borough['WHO_totalfat'].sum() / groceries_borough.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intake of saturated fats should be less than 10% of total energy intake\n",
    "groceries_borough['WHO_saturatedfat'] = 0\n",
    "groceries_borough.loc[(groceries_borough['energy_saturate'] <= 0.1*groceries_borough['energy_tot']), 'WHO_saturatedfat'] = 1\n",
    "groceries_borough['WHO_saturatedfat'].sum() / groceries_borough.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intake of free sugars should be less than 10% of total energy intake\n",
    "groceries_borough['WHO_freesugars'] = 0\n",
    "groceries_borough.loc[(groceries_borough['energy_fat'] <= 0.1*groceries_borough['energy_sugar']), 'WHO_freesugars'] = 1\n",
    "groceries_borough['WHO_freesugars'].sum() / groceries_borough.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c\n",
    "groceries_borough['WHO_salt'] = 0\n",
    "groceries_borough.loc[(groceries_borough['salt'] <= 5), 'WHO_salt'] = 1\n",
    "groceries_borough['WHO_salt'].sum() / groceries_borough.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The London boroughs only fulfill the salt criterion from the WHO recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fancy visualization à base de flipping cards?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a diet score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 : fit a linear regression on the overweight and obesity data with the highest correlated energy_nutrients features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = ['prevalence_obese_reception', 'prevalence_obese_y6', 'f_obese', 'prevalence_overweight_reception', 'prevalence_overweight_y6', 'f_overweight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indicators:\n",
    "    correlation = pd.DataFrame(columns = ['feature', 'R', 'p_value'])\n",
    "    for f in energy_nutrients:\n",
    "        corr = stats.spearmanr(merged_borough[i], merged_borough[f])\n",
    "        corr_data = pd.DataFrame([[f, corr[0], corr[1]]], columns = ['feature', 'R', 'p_value'])\n",
    "        correlation = correlation.append(corr_data, ignore_index = True)\n",
    "    sig_features = correlation[correlation['p_value'] < 0.05]\n",
    "    print(i)\n",
    "    print(sig_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only select the features with a statistically significant Spearman rank correlation (p < 0.05) with almost two indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['energy_carb', 'energy_fibre', 'h_nutrients_calories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weights(merged, label):\n",
    "    X = merged[features]\n",
    "    y = merged[label]\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    hyperparams = {'reg':[0.1, 0.01, 0.001, 0.0001], 'learning_rate':[0.1, 0.05, 0.01]}\n",
    "    scenarios = []\n",
    "    for lr in hyperparams['learning_rate']:\n",
    "        for r in hyperparams['reg']:\n",
    "            scores = cross_validate(SGDRegressor(alpha = r, eta0 = lr),X, y = y, cv = 3,\n",
    "                             scoring=('explained_variance', 'neg_mean_squared_error', 'r2'))\n",
    "            scenario = {'learning_rate':lr, 'regularizer':r,\n",
    "                        'MSE': scores['test_neg_mean_squared_error'],\n",
    "                        'Explained variance': scores['test_explained_variance'],\n",
    "                       'r2' : scores['test_r2']}\n",
    "            #print(scores)\n",
    "            scenarios.append(scenario)\n",
    "\n",
    "    best = np.argmax([np.mean(s['r2']) for s in scenarios])\n",
    "\n",
    "    reg_opt = scenarios[best]['regularizer']\n",
    "    lr_opt = scenarios[best]['learning_rate']\n",
    "    print(reg_opt, lr_opt)\n",
    "    model_opt = SGDRegressor(eta0 = lr_opt, alpha = reg_opt)\n",
    "    model_opt.fit(X,y)\n",
    "    r2 = model_opt.score(X, y)\n",
    "    train_error = np.mean((model_opt.predict(X)-y)**2)\n",
    "    print(label)\n",
    "    print((\"Training error : {}, R2 : {}\").\n",
    "          format(train_error, r2))\n",
    "    return model_opt.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(index = features, columns = indicators)\n",
    "\n",
    "for label in indicators:\n",
    "    weights[label] = find_weights(merged_borough, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(area):\n",
    "    df = area[features].values\n",
    "    score = (df*weights).sum()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries_borough['score1'] = groceries_borough.apply(score, axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "groceries_borough['score1'] = 1 - scaler.fit_transform(groceries_borough[['score1']].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check consistency : plot repartition of 25% lowest and 25% highest scoring areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest = pd.DataFrame(groceries_borough[groceries_borough['score1'] <= groceries_borough['score1'].quantile(0.25)][features]).T\n",
    "highest = pd.DataFrame(groceries_borough[groceries_borough['score1'] >= groceries_borough['score1'].quantile(0.75)][features]).T\n",
    "highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, sharex=False, sharey=False, figsize=(14, 4))\n",
    "\n",
    "for i, f in enumerate(features):\n",
    "    axs[i].bar([0, 1], [lowest.loc[f].mean(), highest.loc[f].mean()], color=['tab:orange', 'tab:green'])\n",
    "    axs[i].set_xticks([0, 1])\n",
    "    axs[i].set_xticklabels(['unhealthiest', 'healthiest'])\n",
    "    axs[i].set_title(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Energy carb\", \"Energy fibre\", \"Entropy nutrients\"]\n",
    "fig = make_subplots(rows=1, cols=3, horizontal_spacing=0.05, vertical_spacing=0.1,\n",
    "                   subplot_titles=(titles[0], titles[1], titles[2]))\n",
    "\n",
    "def add_bar_subplot(f, col):\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[0, 1], \n",
    "        y=[lowest.loc[f].mean(), highest.loc[f].mean()], \n",
    "        marker_color=['#ff7f0e', '#2ca02c'],\n",
    "        hovertemplate = titles[col] + \": %{y:.3f}<br>\" + \"<extra></extra>\"),\n",
    "        row=1, col=col+1)\n",
    "    fig['layout']['xaxis'+str(col+1)].update(tickvals=[0,1], ticktext=['unhealthy', 'healthy'])\n",
    "\n",
    "                  \n",
    "for i, f in enumerate(features):\n",
    "    add_bar_subplot(f, i)\n",
    "\n",
    "fig.update_layout(height=400, width=800, showlegend=False)\n",
    "fig.write_html(\"figures/barplots_score1.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 : fit a linear regression on the obesity datasets with the most consumed f_food_categories features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['f_fruit_veg', 'f_sweets', 'f_grains', 'f_dairy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(index = features, columns = indicators)\n",
    "\n",
    "for label in indicators:\n",
    "    weights[label] = find_weights(merged_borough, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries_borough['score2'] = groceries_borough.apply(score, axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "groceries_borough['score2'] = 1 - scaler.fit_transform(groceries_borough[['score2']].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem : Optimal hyperparameters keep changing through runs. Maybe due to small data?\n",
    "Also, for now we select best hyper-param according to r2 score. should maybe change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest = pd.DataFrame(groceries_borough[groceries_borough['score2'] <= groceries_borough['score2'].quantile(0.25)][features]).T\n",
    "highest = pd.DataFrame(groceries_borough[groceries_borough['score2'] >= groceries_borough['score2'].quantile(0.75)][features]).T\n",
    "highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=4, sharex=False, sharey=False, figsize=(14, 4))\n",
    "\n",
    "for i, f in enumerate(features):\n",
    "    axs[i].bar([0, 1], [lowest.loc[f].mean(), highest.loc[f].mean()], color=['tab:orange', 'tab:green'])\n",
    "    axs[i].set_xticks([0, 1])\n",
    "    axs[i].set_xticklabels(['unhealthiest', 'healthiest'])\n",
    "    axs[i].set_title(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Fruit & veg', 'Sweets', 'Grains', 'Dairy']\n",
    "fig = make_subplots(rows=1, cols=4, horizontal_spacing=0.05, vertical_spacing=0.1,\n",
    "                   subplot_titles=(titles[0], titles[1], titles[2], titles[3]))\n",
    "\n",
    "def add_bar_subplot(f, col):\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[0, 1], \n",
    "        y=[lowest.loc[f].mean(), highest.loc[f].mean()], \n",
    "        marker_color=['#ff7f0e', '#2ca02c'],\n",
    "        hovertemplate = titles[col] + \": %{y:.3f}<br>\" + \"<extra></extra>\"),\n",
    "        row=1, col=col+1)\n",
    "    fig['layout']['xaxis'+str(col+1)].update(tickvals=[0,1], ticktext=['unhealthy', 'healthy'])\n",
    "\n",
    "                  \n",
    "for i, f in enumerate(features):\n",
    "    add_bar_subplot(f, i)\n",
    "\n",
    "fig.update_layout(height=400, width=800, showlegend=False)\n",
    "fig.write_html(\"figures/barplots_score2.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map visualization of the two scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_london(variable, merged_borough):\n",
    "    MAPBOX_ACCESSTOKEN = 'pk.eyJ1Ijoic29zbzk0IiwiYSI6ImNraTdwem80MDFsNXEyc3FzeGMxOHpoZGkifQ.coIFQU-pN6pZJi0GuXnLVw'\n",
    "    merged = map_borough.merge(merged_borough, left_on = 'GSS_CODE', right_on = 'area_id', how = 'inner')\n",
    "    merged = merged.to_crs(epsg=4326) # convert the coordinate reference system to lat/long\n",
    "    lga_json = merged.__geo_interface__ #covert to geoJSON\n",
    "    zmin = merged[variable].min()\n",
    "    zmax = merged[variable].max()\n",
    "    name = merged['NAME']\n",
    "\n",
    "    # Set the data for the map\n",
    "    data = go.Choroplethmapbox(\n",
    "            geojson = lga_json,             #this is your GeoJSON\n",
    "            locations = merged.index,    #the index of this dataframe should align with the 'id' element in your geojson\n",
    "            z = merged[variable], #sets the color value\n",
    "            text = merged.NAME,    #sets text for each shape\n",
    "            colorbar=dict(thickness=20, ticklen=3, tickformat='',outlinewidth=0), #adjusts the format of the colorbar\n",
    "            marker_line_width=1, marker_opacity=0.7, colorscale=\"Viridis\", #adjust format of the plot\n",
    "            zmin=zmin, zmax=zmax,           #sets min and max of the colorbar\n",
    "            hovertemplate = \"<b>%{text}</b><br>\" +\n",
    "                             \"%{z:.0%}<br>\" +\n",
    "                            \"<extra></extra>\")  # sets the format of the text shown when you hover over each shape\n",
    "\n",
    "    # Set the layout for the map\n",
    "    layout = go.Layout(     #format the plot title\n",
    "        mapbox1 = dict(\n",
    "            domain = {'x': [0, 1],'y': [0, 1]}, \n",
    "            center = dict(lat=51.509865 , lon=-0.118092),\n",
    "            accesstoken = MAPBOX_ACCESSTOKEN, \n",
    "            zoom = 8.8),                      \n",
    "        autosize=True,\n",
    "        height=650,\n",
    "        margin=dict(l=0, r=0, t=40, b=0))\n",
    "\n",
    "    # Generate the map\n",
    "    data, layout\n",
    "    fig=go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(\"figures/\" + variable + \"_map.jpeg\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_london('score1', groceries_borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_london('score2', groceries_borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of the two score and selection of the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_borough = pd.merge(merged_borough, groceries_borough[['area_id', 'score1', 'score2']], on='area_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merged_borough[['estimated_diabetes_prevalence', 'score1', 'score2']].corr(method='spearman')\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['score1', 'score2', 'estimated_diabetes_prevalence']\n",
    "features_name = ['Score 1', 'Score 2', 'Diabetes prevalence']\n",
    "colors = ['#3e4989', '#1f9e89', '#b5de2b']\n",
    "titles = [f'Spearman rank correlation = {corr.iloc[1,2]:.3f}',\n",
    "         f'Spearman rank correlation = {corr.iloc[0,1]:.3f}',\n",
    "         f'Spearman rank correlation = {corr.iloc[0,2]:.3f}']\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2, horizontal_spacing=0.1, vertical_spacing=0.1,\n",
    "                specs=[[{\"colspan\": 2}, None], [{}, {}]],\n",
    "                   subplot_titles=(titles[0], titles[1], titles[2]))\n",
    "\n",
    "def add_scatter_subplot(f1, f2, row, col):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=merged_borough[features[f1]], \n",
    "        y=merged_borough[features[f2]],\n",
    "        marker_color = colors[row+col-2],\n",
    "        mode='markers',\n",
    "        hovertemplate = features_name[f1] + \": %{x:.3f}<br>\" + features_name[f2] + \": %{y:.3f}<br>\" + \"<extra></extra>\"),\n",
    "        row=row, col=col)\n",
    "    fig['layout']['xaxis'+str(row+col-1)].update(title_text=features_name[f1], title_standoff=3)\n",
    "    fig['layout']['yaxis'+str(row+col-1)].update(title_text=features_name[f2], title_standoff=3)\n",
    "    \n",
    "add_scatter_subplot(0, 1, 1, 1)\n",
    "add_scatter_subplot(0, 2, 2, 1)\n",
    "add_scatter_subplot(1, 2, 2, 2)\n",
    "\n",
    "fig.update_layout(height=800, width=800, showlegend=False)\n",
    "fig.write_html(\"figures/scatter2D.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As score1 has a biggest Spearman rank correlation coefficient than score2, we will only use score1 in our future analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relate the diet score to economic factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the economic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groceries_poverty = pd.merge(groceries_borough, children_poverty, how = 'inner', on='area_id')\n",
    "\n",
    "boroughs = mapping_code_to_borough.copy()\n",
    "boroughs = pd.merge(boroughs, earnings, how='inner', on='Borough name')\n",
    "groceries_earnings = pd.merge(groceries_borough, boroughs, how = 'inner', left_on='area_id', right_on='Borough Code')\n",
    "\n",
    "boroughs = mapping_code_to_borough.copy()\n",
    "boroughs = pd.merge(boroughs, consumer_expenditure['Food'], how='inner', on='Borough name')\n",
    "groceries_expenditure = pd.merge(groceries_borough, boroughs, how = 'inner', left_on='area_id', right_on='Borough Code')\n",
    "groceries_expenditure.rename(columns={'Food':'food_expenditure'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_borough = pd.merge(merged_borough, groceries_poverty[['area_id', 'child_poverty']], on='area_id')\n",
    "merged_borough = pd.merge(merged_borough, groceries_earnings[['area_id', 'earnings']], on='area_id')\n",
    "merged_borough = pd.merge(merged_borough, groceries_expenditure[['area_id', 'food_expenditure']], on='area_id')\n",
    "merged_borough.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "London Consumer Expenditure Estimates - Detailed Borough Base: consumer expenditure data to 2036 broken down by London borough. We will transform the data concerning food expenditure in percentage of the total expenditure over the year 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_london_data(variable, merged_borough, hovertemplate):\n",
    "    merged = map_borough.merge(merged_borough, left_on = 'GSS_CODE', right_on = 'area_id', how = 'inner')\n",
    "    merged = merged.to_crs(epsg=4326) # convert the coordinate reference system to lat/long\n",
    "    lga_json = merged.__geo_interface__ #covert to geoJSON\n",
    "    zmin = merged[variable].min()\n",
    "    zmax = merged[variable].max()\n",
    "    name = merged['NAME']\n",
    "\n",
    "    # Set the data for the map\n",
    "    data = go.Choroplethmapbox(\n",
    "            geojson = lga_json,             #this is your GeoJSON\n",
    "            locations = merged.index,    #the index of this dataframe should align with the 'id' element in your geojson\n",
    "            z = merged[variable], #sets the color value\n",
    "            text = merged.NAME,    #sets text for each shape\n",
    "            colorbar=dict(thickness=20, ticklen=3, tickformat='',outlinewidth=0), #adjusts the format of the colorbar\n",
    "            marker_line_width=1, marker_opacity=0.7, colorscale=\"Viridis\", #adjust format of the plot\n",
    "            zmin=zmin, zmax=zmax,           #sets min and max of the colorbar\n",
    "            hovertemplate=hovertemplate)  # sets the format of the text shown when you hover over each shape\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_london_layout():\n",
    "    MAPBOX_ACCESSTOKEN = 'pk.eyJ1Ijoic29zbzk0IiwiYSI6ImNraTdwem80MDFsNXEyc3FzeGMxOHpoZGkifQ.coIFQU-pN6pZJi0GuXnLVw'\n",
    "    \n",
    "    # Set the layout for the map\n",
    "    layout = go.Layout(\n",
    "        title = {'font': {'size':24}},  \n",
    "        mapbox1 = dict(\n",
    "            domain = {'x': [0, 1],'y': [0, 1]}, \n",
    "            center = dict(lat=51.509865 , lon=-0.118092),\n",
    "            accesstoken = MAPBOX_ACCESSTOKEN, \n",
    "            zoom = 8.8),                      \n",
    "        autosize=True,\n",
    "        height=650,\n",
    "        margin=dict(l=0, r=0, t=40, b=0))\n",
    "\n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = go.Figure(data=[plot_london_data('earnings', groceries_earnings, \"<b>%{text}</b><br>\"+\"%{z:.0f}£<br>\"+\"<extra></extra>\"), \n",
    "        plot_london_data('child_poverty', groceries_poverty, \"<b>%{text}</b><br>\"+\"%{z:.0f}£<br>\"+\"<extra></extra>\"),\n",
    "          plot_london_data('food_expenditure', groceries_expenditure, \"<b>%{text}</b><br>\"+\"%{z:.0%}<br>\"+\"<extra></extra>\")],\n",
    "       layout = plot_london_layout())\n",
    "\n",
    "plot.update_layout( \n",
    "    updatemenus=[ \n",
    "        dict( \n",
    "            active=0, \n",
    "            buttons=list([  \n",
    "                dict(label=\"Earnings\", \n",
    "                     method=\"update\", \n",
    "                     args=[{\"visible\": [True, False, False]}, \n",
    "                           {\"title\": \"London economic indicators\", \n",
    "                            }]), \n",
    "                dict(label=\"Child poverty\", \n",
    "                     method=\"update\", \n",
    "                     args=[{\"visible\": [False, True, False]}, \n",
    "                           {\"title\": \"London economic indicators\", \n",
    "                            }]),\n",
    "                dict(label=\"Food expenditure\", \n",
    "                     method=\"update\", \n",
    "                     args=[{\"visible\": [False, False, True]}, \n",
    "                           {\"title\": \"London economic indicators\", \n",
    "                            }])\n",
    "            ]), \n",
    "        ) \n",
    "    ]) \n",
    "  \n",
    "plot.write_html(\"figures/economicindicators_map.html\")    \n",
    "plot.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = merged_borough[['score1', 'child_poverty', 'earnings', 'food_expenditure']]\n",
    "features.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['child_poverty', 'earnings', 'food_expenditure','avg_age']\n",
    "weights = find_weights(merged_borough, 'score1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(merged_borough, x='food_expenditure', y='child_poverty', z='earnings',\n",
    "              color='score1', color_continuous_scale=px.colors.sequential.Viridis, width=600, height=500,\n",
    "            labels={\"food_expenditure\": \"Food expenditure\",\n",
    "             \"child_poverty\": \"Child poverty (£)\",\n",
    "             \"earnings\": \"Earnings (£)\",\n",
    "             \"score1\": \"Score 1\"})\n",
    "plot.write_html(\"figures/scatter3d.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding as features for score3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_food_categories = ['energy_tot', 'energy_fat', 'energy_saturate', 'energy_sugar', 'energy_protein', 'energy_carb', \n",
    "                    'energy_fibre', 'h_nutrients_calories']\n",
    "\n",
    "data = np.array([merged_borough['f_beer']]).T\n",
    "for f in f_food_categories:\n",
    "    data = np.concatenate((data, np.array([merged_borough[f]]).T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "data_embedded = TSNE(n_components=3).fit_transform(data)\n",
    "#pca = PCA(n_components=3)\n",
    "#data_embedded = pca.fit_transform(data)\n",
    "\n",
    "data_embedded = pd.DataFrame(data_embedded)\n",
    "data_embedded.columns = ['x', 'y', 'z']\n",
    "data_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(data_embedded, x='x', y='y', z='z')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
